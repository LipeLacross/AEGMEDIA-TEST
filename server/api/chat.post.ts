// server/api/chat.post.ts - Vers√£o FINAL com Tipos Corretos
import { HfInference } from '@huggingface/inference'

interface ChatMessage {
  role: 'user' | 'assistant' | 'system'
  content: string
}

interface ChatRequest {
  message: string
  context?: ChatMessage[]
  sessionId?: string
}

interface ChatResponse {
  reply: string
  timestamp: string
  context: ChatMessage[]
  error?: boolean
  debug?: string
}

// Configura√ß√µes otimizadas para modelos de 2025
const CONFIG = {
  MAX_RETRIES: 3,
  TIMEOUT_MS: 8000,
  RETRY_DELAY_MS: 1500,
  MAX_SESSIONS: 100,
  SESSION_TTL_MS: 30 * 60 * 1000,
  BACKOFF_MULTIPLIER: 2
} as const

// Modelos priorit√°rios atualizados
const STABLE_MODELS = [
  'google/gemma-2-2b-it',
  'meta-llama/Meta-Llama-3-8B-Instruct', // Vers√£o gratuita para uso comercial
  'mistralai/Mistral-7B-Instruct-v0.2',
  'tiiuae/falcon-7b',
  'meta-llama/Llama-2-7B-chat-hf'
] as const


// Type helper para garantir que temos um modelo v√°lido
type ValidModel = typeof STABLE_MODELS[number]

// Valida√ß√£o do token
const validateToken = (token: string | undefined): boolean => {
  return token !== undefined && token.startsWith('hf_') && token.length > 20
}

// Fun√ß√£o para delay com backoff exponencial
const delay = (ms: number): Promise<void> => {
  return new Promise(resolve => setTimeout(resolve, ms))
}

// Fallback responses em portugu√™s otimizado
const getIntelligentFallback = (message: string, errorType?: string): string => {
  const lowerMessage = message.toLowerCase()

  let baseResponse = ''

  if (lowerMessage.includes('pre√ßo') || lowerMessage.includes('custo') || lowerMessage.includes('valor')) {
    baseResponse = `üí∞ **Planos AutoShield:**

‚Ä¢ **Essencial**: R$ 89/m√™s - Cobertura b√°sica completa
‚Ä¢ **Completo**: R$ 149/m√™s - Prote√ß√£o total + benef√≠cios extras  
‚Ä¢ **Premium**: R$ 229/m√™s - M√°xima prote√ß√£o + servi√ßos VIP

üì± Fale conosco: (74) 98125-6120`
  } else if (lowerMessage.includes('cobertura') || lowerMessage.includes('prote√ß√£o')) {
    baseResponse = `üõ°Ô∏è **Prote√ß√£o AutoShield:**

‚Ä¢ Roubo e furto total
‚Ä¢ Rastreamento GPS inteligente
‚Ä¢ Assist√™ncia 24h Brasil
‚Ä¢ Guincho ilimitado
‚Ä¢ Cobertura de vidros

üìû Contato: (74) 98125-6120`
  } else if (lowerMessage.includes('contato') || lowerMessage.includes('falar') || lowerMessage.includes('atendimento')) {
    baseResponse = `üìû **Fale Conosco:**

‚Ä¢ WhatsApp: (74) 98125-6120
‚Ä¢ Email: contato@autoshield.com.br
‚Ä¢ Atendimento 24h dispon√≠vel

Nossa equipe especializada est√° pronta para ajudar!`
  } else {
    baseResponse = `üëã Ol√°! Sou o assistente da AutoShield.

üöó **Como posso ajudar:**
‚Ä¢ Informa√ß√µes sobre planos e pre√ßos
‚Ä¢ Detalhes de cobertura
‚Ä¢ Contrata√ß√£o e atendimento
‚Ä¢ D√∫vidas sobre prote√ß√£o veicular

üì± **Contato direto:** (74) 98125-6120`
  }

  return baseResponse
}

// Fallback de emerg√™ncia
const getEmergencyFallback = (): string => {
  return `üö® **Sistema Temporariamente Indispon√≠vel**

üìû **Contato Imediato:**
WhatsApp: (74) 98125-6120

üí° **Informa√ß√µes R√°pidas:**
‚Ä¢ AutoShield: Prote√ß√£o veicular premium
‚Ä¢ Planos: R$ 89, R$ 149 e R$ 229/m√™s
‚Ä¢ Cobertura 24h em todo Brasil
‚Ä¢ CEO: Felipe Moreira Rios

Nossa equipe est√° dispon√≠vel para ajudar!`
}

// FUN√á√ÉO CORRIGIDA: Tipos seguros para modelos
const tryWithStableModels = async (messages: ChatMessage[]): Promise<string> => {
  for (const model of STABLE_MODELS) {
    try {
      console.log(`ü§ñ Testando modelo: ${model}`)

      // CORRE√á√ÉO PRINCIPAL: model agora √© garantidamente um tipo literal de string
      const response = await Promise.race([
        hf.chatCompletion({
          model, // Agora √© do tipo ValidModel, n√£o pode ser undefined
          messages: messages.map(msg => ({
            role: msg.role as 'user' | 'assistant' | 'system',
            content: msg.content
          })),
          max_tokens: 200,
          temperature: 0.7,
          top_p: 0.9
        }),
        new Promise<never>((_, reject) =>
          setTimeout(() => reject(new Error('TIMEOUT')), CONFIG.TIMEOUT_MS)
        )
      ])

      if (response?.choices?.[0]?.message?.content) {
        console.log(`‚úÖ Sucesso com modelo: ${model}`)
        return response.choices[0].message.content.trim()
      }
    } catch (error: unknown) {
      const errorMessage = error instanceof Error ? error.message : 'Erro desconhecido'
      console.error(`‚ùå Modelo ${model} falhou:`, errorMessage)
      continue
    }
  }

  return '' // Todos os modelos falharam
}

// Fun√ß√£o para limpar sess√µes antigas
const cleanupSessions = (conversationMemory: Map<string, ChatMessage[]>): void => {
  if (conversationMemory.size > CONFIG.MAX_SESSIONS) {
    const keys = Array.from(conversationMemory.keys())
    const keysToDelete = keys.slice(0, Math.floor(CONFIG.MAX_SESSIONS * 0.2))
    keysToDelete.forEach(key => conversationMemory.delete(key))
  }
}

const hf = new HfInference(process.env.HUGGINGFACE_TOKEN)
const conversationMemory = new Map<string, ChatMessage[]>()

export default defineEventHandler(async (event): Promise<ChatResponse> => {
  const startTime = Date.now()

  try {
    const body = await readBody<ChatRequest>(event)
    const { message } = body
    let context = body.context || []
    let sessionId = body.sessionId || Math.random().toString(36).substring(2, 15)

    // Valida√ß√£o de entrada
    if (!message?.trim()) {
      throw createError({
        statusCode: 400,
        statusMessage: 'Mensagem √© obrigat√≥ria'
      })
    }

    // Limpeza peri√≥dica de sess√µes antigas
    cleanupSessions(conversationMemory)

    // Recupera√ß√£o de contexto
    if (conversationMemory.has(sessionId)) {
      context = conversationMemory.get(sessionId) || []
    }

    // Valida√ß√£o do token
    const token = process.env.HUGGINGFACE_TOKEN
    if (!validateToken(token)) {
      console.error('Token Hugging Face inv√°lido ou n√£o configurado')
      const fallbackReply = getIntelligentFallback(message)

      const newContext: ChatMessage[] = [
        ...context.slice(-10),
        { role: 'user' as const, content: message },
        { role: 'assistant' as const, content: fallbackReply }
      ]

      conversationMemory.set(sessionId, newContext)

      return {
        reply: fallbackReply,
        timestamp: new Date().toISOString(),
        context: newContext,
        debug: 'Usando fallback - Token inv√°lido'
      }
    }

// Prompt do sistema totalmente reformulado
const systemPrompt = `Voc√™ √© o Vendedor S√™nior da AutoShield com 15 anos de experi√™ncia. 

**Dados da Empresa:**
- Planos: Essencial (R$89), Completo (R$149), Premium (R$229)
- Coberturas: Roubo, colis√£o, inc√™ndio, assist√™ncia 24h, GPS inteligente
- Diferenciais: App exclusivo, desconto progressivo, carro reserva

**T√©cnicas de Vendas:**
1. Identificar necessidade: Perguntar tipo de ve√≠culo, uso di√°rio, preocupa√ß√µes
2. Oferecer upsell: Ex: "Para seu SUV 2023, recomendo o Premium com cobertura total"
3. Criar urg√™ncia: "Hoje temos 10% de desconto para contrata√ß√£o imediata"
4. Lidar com obje√ß√µes: 
   - "√â caro" ‚Üí Mostrar economia anual vs seguro tradicional
   - "Preciso pensar" ‚Üí Oferecer an√°lise gratuita do ve√≠culo

**Formato de Respostas:**
[In√≠cio] Sauda√ß√£o personalizada
[Meio] Benef√≠cios espec√≠ficos + compara√ß√£o de planos
[Fim] CTA claro + link WhatsApp

**Exemplo de Resposta Profissional:**
"Ol√° [Nome], para seu Corolla 2022 que roda 50km/dia, nosso plano Completo oferece... 
üëâ WhatsApp para contrata√ß√£o imediata: (74) 98125-6120"`

    // Preparar mensagens com tipos seguros
    const messages: ChatMessage[] = [
      {
        role: 'system' as const,
        content: systemPrompt
      },
      ...context.slice(-6),
      {
        role: 'user' as const,
        content: `[PT-BR] ${message}`
      }
    ]

    let reply = ''

    // Tentar com todos os modelos est√°veis
    for (let attempt = 1; attempt <= CONFIG.MAX_RETRIES; attempt++) {
      try {
        console.log(`üîÑ Tentativa ${attempt}/${CONFIG.MAX_RETRIES}`)

        reply = await tryWithStableModels(messages)

        if (reply && reply.length > 10) {
          // Filtrar respostas em ingl√™s
          if (reply.includes('I\'m here to help') ||
              reply.includes('AutoShield company') ||
              reply.toLowerCase().includes('vehicle protection')) {
            console.log('üîç Resposta em ingl√™s detectada, usando fallback')
            reply = getIntelligentFallback(message, 'LANGUAGE_ERROR')
          }
          break
        }
      } catch (error: unknown) {
        const errorMessage = error instanceof Error ? error.message : 'Erro desconhecido'
        console.error(`‚ùå Tentativa ${attempt} falhou:`, errorMessage)

        if (attempt === CONFIG.MAX_RETRIES) {
          reply = getIntelligentFallback(message, 'MODEL_ERROR')
        } else {
          const waitTime = CONFIG.RETRY_DELAY_MS * Math.pow(CONFIG.BACKOFF_MULTIPLIER, attempt - 1)
          await delay(waitTime)
        }
      }
    }

    // Fallback final se todas as tentativas falharam
    if (!reply || reply.length < 10) {
      reply = getIntelligentFallback(message, 'ALL_FAILED')
    }

    // Atualizar contexto
    const newContext: ChatMessage[] = [
      ...context.slice(-10),
      { role: 'user' as const, content: message },
      { role: 'assistant' as const, content: reply }
    ]

    conversationMemory.set(sessionId, newContext)

    const processingTime = Date.now() - startTime
    console.log(`‚úÖ Processamento conclu√≠do em ${processingTime}ms`)

    return {
      reply: reply,
      timestamp: new Date().toISOString(),
      context: newContext
    }

  } catch (error: unknown) {
    console.error('‚ùå Erro cr√≠tico na API:', error)
    return {
      reply: getEmergencyFallback(),
      context: [],
      error: true,
      timestamp: new Date().toISOString()
    }
  }
})
